{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet Deep Learning reconnaisance de la marque Coca-Cola ou Pepsi"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "L'objectif du projet est de faire en sorte que le code différencie de mieux en mieux les images représentant la marque Coca-cola ou Pepsi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importation des dépendances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing.image import img_to_array\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.applications.vgg16 import decode_predictions\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonction permettant de créer le dataset du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(folder):\n",
    "    all_images = []\n",
    "    image_arrays = []\n",
    "    all_labels = []\n",
    "    filenames = []\n",
    "    for class_id, label in enumerate(os.listdir(folder)):\n",
    "        print(class_id, label)\n",
    "        \n",
    "        for filename in glob.glob(folder + '/{}/*'.format(label)):\n",
    "            filenames.append(filename)\n",
    "            im = load_img(filename, target_size=(224, 224))\n",
    "            all_images.append(im)\n",
    "            preprocessed = preprocess_input(img_to_array(im))\n",
    "            image_arrays.append(preprocessed)\n",
    "            all_labels.append(class_id)\n",
    "    X = np.array(image_arrays)\n",
    "    Y = to_categorical(np.array(all_labels))\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 coca\n",
      "1 pepsi\n"
     ]
    }
   ],
   "source": [
    "X, Y = create_dataset('img')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonction permettant d'evaluer une image avec VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image_using_vgg(img_path, vgg):\n",
    "    \"\"\"\n",
    "    Open image, convert it to an array, and run predictions\n",
    "    using a trained model.\n",
    "    \"\"\"\n",
    "    # load an image from file\n",
    "    image = load_img(img_path, target_size=(224, 224))\n",
    "    # convert the image pixels to a numpy array\n",
    "    image = img_to_array(image)\n",
    "    # reshape data for the model\n",
    "    image = image.reshape(\n",
    "        (1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "    image = preprocess_input(image)\n",
    "    y_pred = vgg.predict(image)\n",
    "    labels = decode_predictions(y_pred)\n",
    "    label = labels[0][0]\n",
    "    print(\"class: {}, proba {:.2f}%\".format(label[1], label[2]*100))\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création du modèle VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prédiction sur l'image avec 1 fleur "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class: water_bottle, proba 11.98%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[('n04557648', 'water_bottle', 0.11982704),\n",
       "  ('n03983396', 'pop_bottle', 0.10293057),\n",
       "  ('n03937543', 'pill_bottle', 0.09182911),\n",
       "  ('n03666591', 'lighter', 0.08724539),\n",
       "  ('n03476991', 'hair_spray', 0.079282835)]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_image_using_vgg('img/coca/16988.jpg', model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prédiction sur l'image avec 2 fleurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class: nipple, proba 47.11%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[('n03825788', 'nipple', 0.47108766),\n",
       "  ('n04557648', 'water_bottle', 0.29801768),\n",
       "  ('n04560804', 'water_jug', 0.07877592),\n",
       "  ('n03937543', 'pill_bottle', 0.034561373),\n",
       "  ('n03983396', 'pop_bottle', 0.030775659)]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_image_using_vgg('img/pepsi/41W2XfrKaXL.jpg', model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prédiction sur l'image avec 3 fleurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prédiction sur l'image avec 4 fleurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création du modèle custom en se basant sur VGG16 sans les couches fully-connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_cut = VGG16(weights=\"imagenet\", include_top=False,\n",
    "                input_shape=(224, 224, 3))\n",
    "x = vgg_cut.output\n",
    "# transform matrix into 1-d vector\n",
    "x = Flatten()(x)\n",
    "x = Dense(2, activation='softmax')(x)\n",
    "\n",
    "custom_model = Model(inputs=vgg_cut.input, outputs=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrainement seulement du classifieur et pas des autres couches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in custom_model.layers[:-2]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 50178     \n",
      "=================================================================\n",
      "Total params: 14,764,866\n",
      "Trainable params: 50,178\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "custom_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compilation du modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=SGD(lr=0.0001, momentum=0.9),\n",
    "    metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrainement du modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "179/179 [==============================] - 61s 341ms/step - loss: 5.4061 - acc: 0.6425\n",
      "Epoch 2/5\n",
      "179/179 [==============================] - 63s 351ms/step - loss: 4.8187 - acc: 0.6983\n",
      "Epoch 3/5\n",
      "179/179 [==============================] - 60s 336ms/step - loss: 4.7369 - acc: 0.6983\n",
      "Epoch 4/5\n",
      "179/179 [==============================] - 60s 334ms/step - loss: 3.7536 - acc: 0.7598\n",
      "Epoch 5/5\n",
      "179/179 [==============================] - 60s 336ms/step - loss: 4.5414 - acc: 0.7095\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26983b61828>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_model.fit(X, Y,\n",
    "                 epochs=5, batch_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construction du dataset de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test-img\\coca-25cl.jpg\n",
      "test-img\\coca.jpg\n",
      "test-img\\pepsi 1.jpg\n",
      "test-img\\pepsi 2.jpg\n"
     ]
    }
   ],
   "source": [
    "test_image_arrays = []\n",
    "for filename in glob.glob('test-img/*'):\n",
    "    print(filename)\n",
    "    im = load_img(filename, target_size=(224, 224))\n",
    "    preprocessed = preprocess_input(img_to_array(im))\n",
    "    test_image_arrays.append(preprocessed)\n",
    "X_test = np.array(test_image_arrays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction du dataset de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.]\n",
      "1.0\n",
      "2\n",
      "[1.000000e+00 2.073312e-18]\n",
      "1.0\n",
      "1\n",
      "[0. 1.]\n",
      "1.0\n",
      "2\n",
      "[0. 1.]\n",
      "1.0\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "res = custom_model.predict(X_test)\n",
    "#print(res)\n",
    "for resimg in res:\n",
    "    print(resimg)\n",
    "    print(max(resimg))\n",
    "    print(np.argmax(resimg) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
